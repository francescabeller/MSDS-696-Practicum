{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify Recommendation Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spotify Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\febel\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from spotipy.exceptions import SpotifyException\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn as skl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set account info\n",
    "cid = '81fee852cceb4259910e7d2ff78493c3'\n",
    "secret = 'ad4360215d7641ee809275cc5cdd4a6c'\n",
    "username = 'francescab13'\n",
    "\n",
    "# Connect and create Spotify instance\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=cid, client_secret=secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve track ID's from 'Like' and 'Dislike' playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'track': {'id': '75Q69chmd8CEZbVsA4CDMm'}},\n",
       " {'track': {'id': '38kjIfRtXsUxXyzhsKwX7i'}},\n",
       " {'track': {'id': '1YT8xkroYGNLGR4qhuWLC4'}},\n",
       " {'track': {'id': '76gYk9g0bZj47NyIKzjLF6'}},\n",
       " {'track': {'id': '7tvuLLroI0n6uYBWuFig5d'}}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data from 'Likes' playlist\n",
    "good_ids = []\n",
    "pl_id = 'spotify:playlist:2O6XH1ip37KOllmc1KoYEs'\n",
    "offset = 0\n",
    "\n",
    "while True:\n",
    "    response = sp.playlist_tracks(pl_id,\n",
    "                                  offset=offset,\n",
    "                                  fields='items.track.id,total')\n",
    "    good_ids.append(response['items'])\n",
    "    offset = offset + len(response['items'])\n",
    "\n",
    "    if len(response['items']) == 0:\n",
    "        break\n",
    "\n",
    "# Flatten list of lists of JSON\n",
    "good_flatten = []\n",
    "for sublist in good_ids:\n",
    "    for item in sublist:\n",
    "        good_flatten.append(item)\n",
    "\n",
    "# Check good track ID list\n",
    "good_flatten[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'track': {'id': '1YwNlWLf8auhazSQUDQLFU'}},\n",
       " {'track': {'id': '1xShPgQbOUa98avWJQFDBY'}},\n",
       " {'track': {'id': '3GREm6zSHwKZsJxl0hqbAQ'}},\n",
       " {'track': {'id': '0C6EIiQu8CS4eYtOCMEiAd'}},\n",
       " {'track': {'id': '0puf9yIluy9W0vpMEUoAnN'}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data from 'Dislikes' playlist\n",
    "bad_ids = []\n",
    "pl_id = 'spotify:playlist:58KlzYsGNQoujtrQc2CU5d'\n",
    "offset = 0\n",
    "\n",
    "while True:\n",
    "    response = sp.playlist_tracks(pl_id,\n",
    "                                  offset=offset,\n",
    "                                  fields='items.track.id,total')\n",
    "    bad_ids.append(response['items'])\n",
    "    offset = offset + len(response['items'])\n",
    "\n",
    "    if len(response['items']) == 0:\n",
    "        break\n",
    "\n",
    "# Flatten list of lists of JSON\n",
    "bad_flatten = []\n",
    "for sublist in bad_ids:\n",
    "    for item in sublist:\n",
    "        bad_flatten.append(item)\n",
    "        \n",
    "# Check bad track ID list\n",
    "bad_flatten[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get track characteristic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile list of 'good' track IDs\n",
    "good_id_list = []\n",
    "for i in range(0, len(good_flatten)):\n",
    "    good_id_list.append(good_flatten[i]['track']['id'])\n",
    "good_id_list = [x for x in good_id_list if x]\n",
    "\n",
    "# Retrieve track characteristics\n",
    "good_features = []\n",
    "for i in range(0, len(good_id_list)):\n",
    "    if not good_id_list[i]:\n",
    "        continue\n",
    "    else:\n",
    "        good_features.append(sp.audio_features(good_id_list[i]))\n",
    "\n",
    "# Flatten JSON list\n",
    "good_features_flat = []\n",
    "for sublist in good_features:\n",
    "    for item in sublist:\n",
    "        good_features_flat.append(item)\n",
    "        \n",
    "# Check 'good' features list\n",
    "good_features_flat[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile list of 'bad' track IDs\n",
    "bad_id_list = []\n",
    "for i in range(0, len(bad_flatten)):\n",
    "    bad_id_list.append(bad_flatten[i]['track']['id'])\n",
    "bad_id_list = [x for x in bad_id_list if x]\n",
    "\n",
    "# Retrieve track characteristics\n",
    "bad_features = []\n",
    "for i in range(0, len(bad_id_list)):\n",
    "    if not bad_id_list[i]:\n",
    "        continue\n",
    "    else:\n",
    "        bad_features.append(sp.audio_features(bad_id_list[i]))\n",
    "\n",
    "# Flatten JSON list\n",
    "bad_features_flat = []\n",
    "for sublist in bad_features:\n",
    "    for item in sublist:\n",
    "        bad_features_flat.append(item)\n",
    "        \n",
    "# Check 'bad' features list\n",
    "bad_features_flat[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframes for 'liked' and 'disliked' tracks with audio features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'Like' dataframe\n",
    "like_df = pd.DataFrame.from_records(good_features_flat)\n",
    "\n",
    "# Retrieve song and artist names to add to dataframe\n",
    "good_song_names = []\n",
    "good_artists = []\n",
    "for index, row in like_df.iterrows():\n",
    "    try:\n",
    "        response = sp.track(str(row['uri']))\n",
    "        good_song_names.append(response['name'])\n",
    "        good_artists.append(response['artists'][0]['name'])\n",
    "    except SpotifyException as e:\n",
    "        good_song_names.append('Unknown')\n",
    "        good_artists.append('Unknown')\n",
    "\n",
    "# Create 'song_name' and 'artist' columns\n",
    "like_df['song_name'] = good_song_names\n",
    "like_df['artist'] = good_artists\n",
    "\n",
    "# Check dataframe\n",
    "like_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'Dislike' dataframe\n",
    "dislike_df = pd.DataFrame.from_records(bad_features_flat)\n",
    "\n",
    "# Retrieve song and artist names to add to dataframe\n",
    "bad_song_names = []\n",
    "bad_artists = []\n",
    "for index, row in dislike_df.iterrows():\n",
    "    try:\n",
    "        response = sp.track(str(row['uri']))\n",
    "        bad_song_names.append(response['name'])\n",
    "        bad_artists.append(response['artists'][0]['name'])\n",
    "    except SpotifyException as e:\n",
    "        bad_song_names.append('Unknown')\n",
    "        bad_artists.append('Unknown')\n",
    "\n",
    "# Create 'song_name' and 'artist' columns\n",
    "dislike_df['song_name'] = bad_song_names\n",
    "dislike_df['artist'] = bad_artists\n",
    "\n",
    "# Check dataframe\n",
    "dislike_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the function\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "like_profile = ProfileReport(like_df, title='Liked Songs Pandas Profiling Report', explorative = True)\n",
    "like_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dislike_profile = ProfileReport(dislike_df, title='Disliked Songs Pandas Profiling Report', explorative = True)\n",
    "dislike_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create list of audio feature column names\n",
    "trait_cols = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness',\n",
    "             'liveness', 'valence']\n",
    "discrete_trait_cols = ['key', 'mode', 'tempo', 'time_signature']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dist Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(trait_cols), figsize=(16,12))\n",
    "\n",
    "for i, col_val in enumerate(trait_cols):\n",
    "\n",
    "    sns.distplot(like_df[col_val], hist=True, ax=ax[i])\n",
    "    ax[i].set_title('Freq dist '+col_val, fontsize=10)\n",
    "    ax[i].set_xlabel(col_val, fontsize=8)\n",
    "    ax[i].set_ylabel('Count', fontsize=8)\n",
    "\n",
    "plt.savefig('like_dist_plots.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(trait_cols), figsize=(16,12))\n",
    "\n",
    "for i, col_val in enumerate(trait_cols):\n",
    "\n",
    "    sns.distplot(dislike_df[col_val], hist=True, ax=ax[i])\n",
    "    ax[i].set_title('Freq dist '+col_val, fontsize=10)\n",
    "    ax[i].set_xlabel(col_val, fontsize=8)\n",
    "    ax[i].set_ylabel('Count', fontsize=8)\n",
    "\n",
    "plt.savefig('dislike_dist_plots.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pair Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "like_pairplot = sns.pairplot(like_df[trait_cols])\n",
    "like_pairplot.savefig(\"like_pairplot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dislike_pairplot = sns.pairplot(dislike_df[trait_cols])\n",
    "dislike_pairplot.savefig(\"dislike_pairplot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations\n",
    "corr = like_df[trait_cols].corr()\n",
    " \n",
    "# Heatmap\n",
    "like_corr_heatmap = sns.heatmap(corr)\n",
    "figure = like_corr_heatmap.get_figure()    \n",
    "figure.savefig('like_corr_heatmap.png', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations\n",
    "corr = dislike_df[trait_cols].corr()\n",
    " \n",
    "# Heatmap\n",
    "dislike_corr_heatmap = sns.heatmap(corr)\n",
    "figure = dislike_corr_heatmap.get_figure()    \n",
    "figure.savefig('dislike_corr_heatmap.png', dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency Plots (Discrete Variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2)\n",
    "sns.countplot(like_df['key'], ax=ax[0,0])\n",
    "sns.countplot(like_df['mode'], ax=ax[0,1])\n",
    "sns.countplot(like_df['time_signature'], ax=ax[1,0])\n",
    "fig.show()\n",
    "fig.savefig('like_freq_plots.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2)\n",
    "sns.countplot(dislike_df['key'], ax=ax[0,0])\n",
    "sns.countplot(dislike_df['mode'], ax=ax[0,1])\n",
    "sns.countplot(dislike_df['time_signature'], ax=ax[1,0])\n",
    "fig.show()\n",
    "fig.savefig('dislike_freq_plots.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation/Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign tags to liked and disliked songs\n",
    "like_df['target'] = 1\n",
    "dislike_df['target'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create combined dataframe\n",
    "dfs = [like_df, dislike_df]\n",
    "full_df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(full_df, test_size = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define feature sets\n",
    "features = ['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n",
    "              'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature']\n",
    "x_train = train[features]\n",
    "y_train = train[\"target\"]\n",
    "x_test = test[features]\n",
    "y_test = test[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = skl.tree.DecisionTreeClassifier(min_samples_split=100)\n",
    "dt = dtc.fit(x_train, y_train)\n",
    "y_pred = dtc.predict(x_test)\n",
    "score = skl.metrics.accuracy_score(y_test, y_pred) * 100\n",
    "print(\"Accuracy using Decision Tree: \", round(score, 1), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = skl.neighbors.KNeighborsClassifier(3)\n",
    "knn.fit(x_train, y_train)\n",
    "knn_pred = knn.predict(x_test)\n",
    "score = skl.metrics.accuracy_score(y_test, knn_pred) * 100\n",
    "print(\"Accuracy using Knn Tree: \", round(score, 1), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost/Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "ada = skl.ensemble.AdaBoostClassifier(n_estimators=100)\n",
    "ada.fit(x_train, y_train)\n",
    "ada_pred = ada.predict(x_test)\n",
    "\n",
    "score = skl.metrics.accuracy_score(y_test, ada_pred) * 100\n",
    "print(\"Accuracy using ada: \", round(score, 1), \"%\")\n",
    "gbc = skl.ensemble.GradientBoostingClassifier(n_estimators=100, learning_rate=.1, max_depth=1, random_state=0)\n",
    "gbc.fit(x_train, y_train)\n",
    "predicted = gbc.predict(x_test)\n",
    "score = accuracy_score(y_test, predicted)*100\n",
    "print(\"Accuracy using Gbc: \", round(score, 1), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn; print(\"Scikit-Learn\", sklearn.__version__)\n",
    "import scipy; print(\"Scikit-Learn\", scipy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
